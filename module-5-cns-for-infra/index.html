



<!DOCTYPE html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      <meta http-equiv="x-ua-compatible" content="ie=edge">
      
      
        <link rel="canonical" href="https://dmesser.github.io/ocp-3.7-cns-3.6-lab/module-5-cns-for-infra/">
      
      
      
        <meta name="lang:clipboard.copy" content="Copy to clipboard">
      
        <meta name="lang:clipboard.copied" content="Copied to clipboard">
      
        <meta name="lang:search.language" content="en">
      
        <meta name="lang:search.result.none" content="No matching documents">
      
        <meta name="lang:search.result.one" content="1 matching document">
      
        <meta name="lang:search.result.other" content="# matching documents">
      
        <meta name="lang:search.tokenizer" content="[\s\-]+">
      
      <link rel="shortcut icon" href="../img/favicon.ico">
      <meta name="generator" content="mkdocs-0.17.2, mkdocs-material-2.2.6">
    
    
      
        <title>Module 5 - Persistent Storage for Infrastructure - Container-Native Storage 3.6 on OpenShift Container Platform 3.7 Hands-on Lab</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/application.6525f7f6.css">
      
        <link rel="stylesheet" href="../assets/stylesheets/application-palette.792431c1.css">
      
    
    
      <script src="../assets/javascripts/modernizr.1aa3b519.js"></script>
    
    
      
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700|Roboto+Mono">
        <style>body,input{font-family:"Roboto","Helvetica Neue",Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono","Courier New",Courier,monospace}</style>
      
      <link rel="stylesheet" href="https://fonts.googleapis.com/icon?family=Material+Icons">
    
    
    
  </head>
  
    
    
    
      <body data-md-color-primary="deep-orange" data-md-color-accent="indigo">
    
  
    <svg class="md-svg">
      <defs>
        
        
      </defs>
    </svg>
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="drawer">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="search">
    <label class="md-overlay" data-md-component="overlay" for="drawer"></label>
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex">
      <div class="md-flex__cell md-flex__cell--shrink">
        <a href="https://dmesser.github.io/ocp-3.7-cns-3.6-lab/" title="Container-Native Storage 3.6 on OpenShift Container Platform 3.7 Hands-on Lab" class="md-header-nav__button md-logo">
          
            <img src="../img/shadowman_rgb.png" width="24" height="24">
          
        </a>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
          
            
              <span class="md-header-nav__topic">
                Container-Native Storage 3.6 on OpenShift Container Platform 3.7 Hands-on Lab
              </span>
              <span class="md-header-nav__topic">
                Module 5 - Persistent Storage for Infrastructure
              </span>
            
          
        </div>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        
          
            <label class="md-icon md-icon--search md-header-nav__button" for="search"></label>
            
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="search"></label>
  <div class="md-search__inner">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" required placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="query">
      <label class="md-icon md-search__icon" for="search"></label>
      <button type="reset" class="md-icon md-search__icon" data-md-component="reset">&#xE5CD;</button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="result">
          <div class="md-search-result__meta">
            Type to start searching
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
          
        
      </div>
      
    </div>
  </nav>
</header>
    
    <div class="md-container">
      
        
      
      
        

  

<nav class="md-tabs md-tabs--active" data-md-component="tabs">
  <div class="md-tabs__inner md-grid">
    <ul class="md-tabs__list">
      
        
  <li class="md-tabs__item">
    
      <a href=".." title="Overview" class="md-tabs__link">
        Overview
      </a>
    
  </li>

      
        
  
  
    <li class="md-tabs__item">
      
        <a href="../module-1-ocp-environment/" title="Modules" class="md-tabs__link md-tabs__link--active">
          Modules
        </a>
      
    </li>
  

      
    </ul>
  </div>
</nav>
      
      <main class="md-main">
        <div class="md-main__inner md-grid" data-md-component="container">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="drawer">
    <span class="md-nav__button md-logo">
      
        <img src="../img/shadowman_rgb.png" width="24" height="24">
      
    </span>
    Container-Native Storage 3.6 on OpenShift Container Platform 3.7 Hands-on Lab
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      


  <li class="md-nav__item">
    <a href=".." title="Overview" class="md-nav__link">
      Overview
    </a>
  </li>

    
      
      
      

  


  <li class="md-nav__item md-nav__item--active md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-2" type="checkbox" id="nav-2" checked>
    
    <label class="md-nav__link" for="nav-2">
      Modules
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-2">
        Modules
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../module-1-ocp-environment/" title="Module 1 - OpenShift Environment" class="md-nav__link">
      Module 1 - OpenShift Environment
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../module-2-deploy-cns/" title="Module 2 - Deploying Container-Native Storage" class="md-nav__link">
      Module 2 - Deploying Container-Native Storage
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../module-3-cns-for-apps/" title="Module 3 - Persistent Storage for Apps" class="md-nav__link">
      Module 3 - Persistent Storage for Apps
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../module-4-cluster-ops/" title="Module 4 - Cluster Operations" class="md-nav__link">
      Module 4 - Cluster Operations
    </a>
  </li>

        
          
          
          

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-toggle md-nav__toggle" data-md-toggle="toc" type="checkbox" id="toc">
    
    
      <label class="md-nav__link md-nav__link--active" for="toc">
        Module 5 - Persistent Storage for Infrastructure
      </label>
    
    <a href="./" title="Module 5 - Persistent Storage for Infrastructure" class="md-nav__link md-nav__link--active">
      Module 5 - Persistent Storage for Infrastructure
    </a>
    
      
<nav class="md-nav md-nav--secondary">
  
  
  
    <label class="md-nav__title" for="toc">Table of contents</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#openshift-registry-on-cns" title="OpenShift Registry on CNS" class="md-nav__link">
    OpenShift Registry on CNS
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#openshift-loggingmetrics-on-cns-block-storage" title="OpenShift Logging/Metrics on CNS block storage" class="md-nav__link">
    OpenShift Logging/Metrics on CNS block storage
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#completing-gluster-block-setup" title="Completing gluster-block setup" class="md-nav__link">
    Completing gluster-block setup
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#deploying-openshift-metrics-with-persistent-storage-from-cns" title="Deploying OpenShift Metrics with Persistent Storage from CNS" class="md-nav__link">
    Deploying OpenShift Metrics with Persistent Storage from CNS
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#deploying-openshift-logging-with-persistent-storage-from-cns" title="Deploying OpenShift Logging with Persistent Storage from CNS" class="md-nav__link">
    Deploying OpenShift Logging with Persistent Storage from CNS
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
      
      
    </ul>
  
</nav>
    
  </li>

        
      </ul>
    </nav>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary">
  
  
  
    <label class="md-nav__title" for="toc">Table of contents</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#openshift-registry-on-cns" title="OpenShift Registry on CNS" class="md-nav__link">
    OpenShift Registry on CNS
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#openshift-loggingmetrics-on-cns-block-storage" title="OpenShift Logging/Metrics on CNS block storage" class="md-nav__link">
    OpenShift Logging/Metrics on CNS block storage
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#completing-gluster-block-setup" title="Completing gluster-block setup" class="md-nav__link">
    Completing gluster-block setup
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#deploying-openshift-metrics-with-persistent-storage-from-cns" title="Deploying OpenShift Metrics with Persistent Storage from CNS" class="md-nav__link">
    Deploying OpenShift Metrics with Persistent Storage from CNS
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#deploying-openshift-logging-with-persistent-storage-from-cns" title="Deploying OpenShift Logging with Persistent Storage from CNS" class="md-nav__link">
    Deploying OpenShift Logging with Persistent Storage from CNS
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
      
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                
                  <h1>Module 5 - Persistent Storage for Infrastructure</h1>
                
                <div class="admonition summary">
<p class="admonition-title">Overview</p>
<p>In this module you will learn how to use Container-Native Storage to serve storage for OpenShift internal infrastructure.<br />
This module does not have any pre-requisites.</p>
</div>
<h2 id="openshift-registry-on-cns">OpenShift Registry on CNS<a class="headerlink" href="#openshift-registry-on-cns" title="Permanent link">#</a></h2>
<p>The Registry in OpenShift is used to store all images that result of Source-to-Image deployments as well as custom container images.<br />
It runs as one or more containers in specific Infrastructure Nodes or Master Nodes in OpenShift.</p>
<p>As explorerd in Module 1, by default the registry uses a hosts local storage (<code>emptyDir</code>) which makes it prone to outages. To avoid such outages the storage needs to be <strong>persistent</strong> and <strong>shared</strong> in order to survive Registry pod restarts and scale-out.</p>
<p>What we want to achieve is a setup like depicted in the following diagram:</p>
<p><a href="../img/scaleout_registry_on_cns.png"><img alt="OpenShift Registry on CNS" src="../img/scaleout_registry_on_cns.png" /></a></p>
<p>This can be achieved with CNS simply by making the registry pods refer to a PVC in access mode <em>RWX</em> based on CNS.<br />
Before OpenShift Container Platform 3.6 this had to be done manually on an existing CNS cluster.</p>
<p>With <code>openshift-ansible</code> you now have this setup task automated. The playbooks that implement this will deploy a <strong>separate CNS cluster</strong>, preferably on the <em>Infrastructure Nodes</em>, create a <code>PVC</code> and update the Registry <code>DeploymentConfig</code> to mount the associated <code>PV</code> which is where container images will then be stored.</p>
<div class="admonition caution">
<p class="admonition-title">Important</p>
<p>This method is potentially disruptive. The registry will be re-deployed in this process and may temporarily be unavailable.<br />
Migration of the data will in the future be taken care of by <code>openshift-ansible</code>. Currently there is bug that prevents this from happening but it should be resolved soon.</p>
</div>
<p>&#8680; Review the <code>openshift-ansible</code> inventory file in <code>/etc/ansible/ocp-with-glusterfs-registry</code> that has been prepared in your environment:</p>
<p><kbd>/etc/ansible/ocp-with-glusterfs-registry:</kbd></p>
<div class="codehilite"><pre><span></span><span class="k">[OSEv3:children]</span>
<span class="na">masters</span>
<span class="na">nodes</span>
<span class="hll"><span class="na">glusterfs_registry</span>
</span>
<span class="k">[OSEv3:vars]</span>
<span class="na">deployment_type</span><span class="o">=</span><span class="s">openshift-enterprise</span>
<span class="na">containerized</span><span class="o">=</span><span class="s">true</span>
<span class="na">openshift_image_tag</span><span class="o">=</span><span class="s">v3.6.173.0.21</span>
<span class="na">openshift_master_identity_providers</span><span class="o">=</span><span class="s">[{&#39;name&#39;: &#39;htpasswd&#39;, &#39;login&#39;: &#39;true&#39;, &#39;challenge&#39;: &#39;true&#39;, &#39;kind&#39;: &#39;HTPasswdPasswordIdentityProvider&#39;, &#39;filename&#39;: &#39;/etc/origin/master/htpasswd&#39;}]</span>
<span class="na">openshift_master_htpasswd_users</span><span class="o">=</span><span class="s">{&#39;developer&#39;: &#39;$apr1$bKWroIXS$/xjq07zVg9XtH6/VKuh6r/&#39;,&#39;operator&#39;: &#39;$apr1$bKWroIXS$/xjq07zVg9XtH6/VKuh6r/&#39;}</span>
<span class="na">openshift_master_default_subdomain</span><span class="o">=</span><span class="s">&#39;cloudapps.52.59.170.248.xip.io&#39;</span>
<span class="na">openshift_router_selector</span><span class="o">=</span><span class="s">&#39;role=master&#39;</span>
<span class="na">openshift_hosted_router_wait</span><span class="o">=</span><span class="s">false</span>
<span class="hll"><span class="na">openshift_registry_selector</span><span class="o">=</span><span class="s">&#39;role=infra&#39;</span>
</span><span class="hll"><span class="na">openshift_hosted_registry_wait</span><span class="o">=</span><span class="s">false</span>
</span><span class="hll"><span class="na">openshift_hosted_registry_storage_volume_size</span><span class="o">=</span><span class="s">10Gi</span>
</span><span class="na">openshift_hosted_registry_storage_glusterfs_swap</span><span class="o">=</span><span class="s">true</span>
<span class="na">openshift_hosted_registry_storage_glusterfs_swapcopy</span><span class="o">=</span><span class="s">true</span>
<span class="na">openshift_metrics_install_metrics</span><span class="o">=</span><span class="s">false</span>
<span class="na">openshift_metrics_hawkular_hostname</span><span class="o">=</span><span class="s">&quot;hawkular-metrics.{{ openshift_master_default_subdomain }}&quot;</span>
<span class="na">openshift_metrics_cassandra_storage_type</span><span class="o">=</span><span class="s">pv</span>
<span class="na">openshift_metrics_cassandra_pvc_size</span><span class="o">=</span><span class="s">10Gi</span>
<span class="na">openshift_logging_install_logging</span><span class="o">=</span><span class="s">false</span>
<span class="na">openshift_logging_es_pvc_size</span><span class="o">=</span><span class="s">10Gi</span>
<span class="na">openshift_logging_es_pvc_dynamic</span><span class="o">=</span><span class="s">true</span>
<span class="na">openshift_storage_glusterfs_image</span><span class="o">=</span><span class="s">rhgs3/rhgs-server-rhel7</span>
<span class="na">openshift_storage_glusterfs_version</span><span class="o">=</span><span class="s">3.3.0-362</span>
<span class="hll"><span class="na">openshift_storage_glusterfs_heketi_image</span><span class="o">=</span><span class="s">rhgs3/rhgs-volmanager-rhel7</span>
</span><span class="hll"><span class="na">openshift_storage_glusterfs_heketi_version</span><span class="o">=</span><span class="s">3.3.0-364</span>
</span><span class="hll"><span class="na">openshift_storage_glusterfs_registry_namespace</span><span class="o">=</span><span class="s">infra-storage</span>
</span><span class="hll"><span class="na">openshift_storage_glusterfs_registry_storageclass</span><span class="o">=</span><span class="s">false</span>
</span><span class="hll"><span class="na">openshift_storage_glusterfs_registry_block_deploy</span><span class="o">=</span><span class="s">true</span>
</span><span class="hll"><span class="na">openshift_storage_glusterfs_registry_block_version</span><span class="o">=</span><span class="s">3.3.0-362</span>
</span><span class="na">openshift_storage_glusterfs_registry_block_host_vol_create</span><span class="o">=</span><span class="s">true</span>
<span class="na">openshift_storage_glusterfs_registry_block_host_vol_size</span><span class="o">=</span><span class="s">20</span>
<span class="na">openshift_docker_additional_registries</span><span class="o">=</span><span class="s">mirror.lab:5555</span>
<span class="na">openshift_docker_insecure_registries</span><span class="o">=</span><span class="s">mirror.lab:5555</span>
<span class="na">oreg_url</span><span class="o">=</span><span class="s">mirror.lab:5555/openshift3/ose-${component}:${version}</span>
<span class="na">osm_etcd_image</span><span class="o">=</span><span class="s">mirror.lab:5555/rhel7/etcd</span>
<span class="na">openshift_service_catalog_image_prefix</span><span class="o">=</span><span class="s">mirror.lab:5555/openshift3/ose-</span>
<span class="na">openshift_cli_image</span><span class="o">=</span><span class="s">mirror.lab:5555/openshift3/ose</span>
<span class="na">osm_image</span><span class="o">=</span><span class="s">mirror.lab:5555/openshift3/ose</span>
<span class="na">openshift_examples_modify_imagestreams</span><span class="o">=</span><span class="s">false</span>
<span class="na">openshift_disable_check</span><span class="o">=</span><span class="s">disk_availability,memory_availability,docker_image_availability</span>
<span class="na">openshift_enable_service_catalog</span><span class="o">=</span><span class="s">true</span>
<span class="na">openshift_template_service_broker_namespaces</span><span class="o">=</span><span class="s">[&#39;openshift&#39;]</span>
<span class="na">template_service_broker_install</span><span class="o">=</span><span class="s">true</span>
<span class="na">ansible_service_broker_install</span><span class="o">=</span><span class="s">false</span>

<span class="k">[masters]</span>
<span class="na">master.lab openshift_public_hostname</span><span class="o">=</span><span class="s">52.59.170.248.xip.io openshift_hostname=master.lab openshift_ip=10.0.1.100 openshift_public_ip=52.59.170.248</span>

<span class="k">[masters:vars]</span>
<span class="na">openshift_schedulable</span><span class="o">=</span><span class="s">true</span>
<span class="na">openshift_node_labels</span><span class="o">=</span><span class="s">&quot;{&#39;role&#39;: &#39;master&#39;}&quot;</span>

<span class="k">[etcd:children]</span>
<span class="na">masters</span>

<span class="k">[nodes]</span>
<span class="na">master.lab openshift_public_hostname</span><span class="o">=</span><span class="s">52.59.170.248.xip.io openshift_hostname=master.lab openshift_ip=10.0.1.100 openshift_public_ip=52.59.170.248</span>
<span class="na">infra-1.lab openshift_hostname</span><span class="o">=</span><span class="s">infra-1.lab openshift_ip=10.0.2.101 openshift_node_labels=&quot;{&#39;role&#39;: &#39;infra&#39;}&quot;</span>
<span class="na">infra-2.lab openshift_hostname</span><span class="o">=</span><span class="s">infra-2.lab openshift_ip=10.0.3.102 openshift_node_labels=&quot;{&#39;role&#39;: &#39;infra&#39;}&quot;</span>
<span class="na">infra-3.lab openshift_hostname</span><span class="o">=</span><span class="s">infra-3.lab openshift_ip=10.0.4.103 openshift_node_labels=&quot;{&#39;role&#39;: &#39;infra&#39;}&quot;</span>
<span class="na">node-1.lab openshift_hostname</span><span class="o">=</span><span class="s">node-1.lab openshift_ip=10.0.2.201 openshift_node_labels=&quot;{&#39;role&#39;: &#39;app&#39;}&quot;</span>
<span class="na">node-2.lab openshift_hostname</span><span class="o">=</span><span class="s">node-2.lab openshift_ip=10.0.3.202 openshift_node_labels=&quot;{&#39;role&#39;: &#39;app&#39;}&quot;</span>
<span class="na">node-3.lab openshift_hostname</span><span class="o">=</span><span class="s">node-3.lab openshift_ip=10.0.4.203 openshift_node_labels=&quot;{&#39;role&#39;: &#39;app&#39;}&quot;</span>
<span class="na">node-4.lab openshift_hostname</span><span class="o">=</span><span class="s">node-4.lab openshift_ip=10.0.2.204 openshift_node_labels=&quot;{&#39;role&#39;: &#39;app&#39;}&quot;</span>
<span class="na">node-5.lab openshift_hostname</span><span class="o">=</span><span class="s">node-5.lab openshift_ip=10.0.3.205 openshift_node_labels=&quot;{&#39;role&#39;: &#39;app&#39;}&quot;</span>
<span class="hll"><span class="na">node-6.lab openshift_hostname</span><span class="o">=</span><span class="s">node-6.lab openshift_ip=10.0.4.206 openshift_node_labels=&quot;{&#39;role&#39;: &#39;app&#39;}&quot;</span>
</span><span class="hll">
</span><span class="hll"><span class="k">[glusterfs_registry]</span>
</span><span class="hll"><span class="na">infra-1.lab glusterfs_ip</span><span class="o">=</span><span class="s">10.0.2.101 glusterfs_zone=1 glusterfs_devices=&#39;[ &quot;/dev/xvdc&quot; ]&#39;</span>
</span><span class="hll"><span class="na">infra-2.lab glusterfs_ip</span><span class="o">=</span><span class="s">10.0.3.102 glusterfs_zone=2 glusterfs_devices=&#39;[ &quot;/dev/xvdc&quot; ]&#39;</span>
</span><span class="na">infra-3.lab glusterfs_ip</span><span class="o">=</span><span class="s">10.0.4.103 glusterfs_zone=3 glusterfs_devices=&#39;[ &quot;/dev/xvdc&quot; ]&#39;</span>
</pre></div>


<p>The highlighted lines indicate the vital options in the inventory file to instruct <code>openshift-ansible</code> to deploy this setup.</p>
<ul>
<li>a hostgroup called <code>[glusterfs_registry]</code> is created with all those OpenShift nodes that are designed to run CNS for Registry and other infrastructure</li>
<li>an instruction to trigger deployment of CNS for the registry (<code>openshift_hosted_registry_storage_kind=glusterfs</code>)</li>
<li>a custom name for the namespace is provided in which the CNS pods will live (<code>openshift_storage_glusterfs_registry_namespace</code>, optional)</li>
<li>any existing registry backend will be swapped out for a CNS volume (<code>openshift_hosted_registry_storage_glusterfs_swap</code>, default <code>false</code>)</li>
<li>any existing data in an existing registry will be copied to the CNS volume (<code>openshift_hosted_registry_storage_glusterfs_swapcopy</code>, default <code>true</code>)</li>
<li>the <code>gluster-block</code> provisioner is enabled (<code>openshift_storage_glusterfs_registry_block_deploy</code>) and a version is selected (<code>openshift_storage_glusterfs_registry_block_version</code>)</li>
<li>a 20GiB volume that <code>gluster-block</code> will use to back iSCSI LUNs will be created (<code>openshift_storage_glusterfs_registry_block_host_vol_create</code>, <code>openshift_storage_glusterfs_registry_block_host_vol_size</code>)</li>
</ul>
<p>Hosts in the <code>[glusterfs_registry]</code> group will run the CNS cluster specifically created for OpenShift Infrastructure. Just like in Module 2, each host gets specific information about the free block device to use for CNS and the failure zone it resides in (the infrastructure nodes are also hosted in 3 different Availability Zones)<br />
The option <code>openshift_hosted_registry_storage_kind=glusterfs</code> will cause the registry to re-deployed with a <code>PVC</code> served by this cluster.</p>
<p>&#8680; First ensure that from an Ansible-perspective the required nodes are reachable</p>
<div class="codehilite"><pre><span></span>ansible -i /etc/ansible/ocp-with-glusterfs-registry glusterfs_registry -m ping
</pre></div>


<p>All 3 OpenShift infrastructure nodes should respond:</p>
<div class="codehilite"><pre><span></span>infra-3.lab | SUCCESS =&gt; {
    &quot;changed&quot;: false,
    &quot;ping&quot;: &quot;pong&quot;
}
infra-1.lab | SUCCESS =&gt; {
    &quot;changed&quot;: false,
    &quot;ping&quot;: &quot;pong&quot;
}
infra-2.lab | SUCCESS =&gt; {
    &quot;changed&quot;: false,
    &quot;ping&quot;: &quot;pong&quot;
}
</pre></div>


<p>&#8680; Enable the Master to be schedulable:</p>
<div class="codehilite"><pre><span></span>oadm manage-node master.lab --schedulable=true
</pre></div>


<div class="admonition important">
<p class="admonition-title">Why does the master need to be schedulable?</p>
<p>This is a very simple lab environment :)<br />
There is no sophisticated external load-balancing across the infrastructure nodes in place.<br />
That&rsquo;s why the OpenShift router will run on the master node. The router will get re-deployed when executing the following playbook.<br />
So making the master accept pods again we ensure the re-deployed router finds it&rsquo;s place again.</p>
</div>
<p>&#8680; Run the CNS registry playbook that ships with <code>openshift-ansible</code>:</p>
<div class="codehilite"><pre><span></span>ansible-playbook -i /etc/ansible/ocp-with-glusterfs-registry \
/usr/share/ansible/openshift-ansible/playbooks/byo/openshift-glusterfs/registry.yml
</pre></div>


<p>This creates a new CNS deployment just for infrastructure workloads on the infrastructure nodes. This will take 6-7 minutes to complete and also create <code>PersistentVolume</code> and <code>PersistentVolumeClaim</code> objects for CNS volume that will serve the registry as a backend.</p>
<p>&#8680; Now, run the following playbook to update the registry:</p>
<div class="codehilite"><pre><span></span>ansible-playbook -i /etc/ansible/ocp-with-glusterfs-registry /usr/share/ansible/openshift-ansible/playbooks/byo/openshift-cluster/openshift-hosted.yml
</pre></div>


<p>This will take another 2-3 minutes.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Currently there is a bug in <code>openshift-ansible</code> that will cause this playbook to fail when attempting to migrate data from the existing registry. The task <code>Activate registry maintenance mode</code> will fail. Nevertheless the registry is updated like you will see below.</p>
</div>
<p>&#8680; Disable scheduling on the Master again:</p>
<div class="codehilite"><pre><span></span>oadm manage-node master.lab --schedulable=false
</pre></div>


<p>Now you have a Registry that uses CNS to store container images. It has automatically been scaled to 3 pods for high availability too.</p>
<p>&#8680; Log in as <code>operator</code> in the <code>default</code> namespace</p>
<div class="codehilite"><pre><span></span>oc login -u operator -n default
</pre></div>


<p>&#8680; Verify a new version of the registry&rsquo;s <code>DeploymentConfig</code> is running:</p>
<div class="codehilite"><pre><span></span>oc get deploymentconfig/docker-registry
</pre></div>


<p>It should say:</p>
<div class="codehilite"><pre><span></span>NAME              REVISION   DESIRED   CURRENT   TRIGGERED BY
docker-registry   2          1         1         config
</pre></div>


<p>&#8680; You can review the details and see how the <code>PVC</code> backs the registry by executing this command</p>
<div class="codehilite"><pre><span></span>oc describe deploymentconfig/docker-registry
</pre></div>


<div class="codehilite"><pre><span></span>Name:       docker-registry
Namespace:  default
Created:    40 minutes ago
Labels:     docker-registry=default
Annotations:    &lt;none&gt;
Latest Version: 2
Selector:   docker-registry=default
Replicas:   3
Triggers:   Config
Strategy:   Rolling
Template:
Pod Template:
  Labels:       docker-registry=default
  Service Account:  registry
  Containers:
   registry:
    Image:  mirror.lab:5555/openshift3/ose-docker-registry:v3.7.14
    Port:   5000/TCP
    Requests:
      cpu:  100m
      memory:   256Mi
    Liveness:   http-get https://:5000/healthz delay=10s timeout=5s period=10s #success=1 #failure=3
    Readiness:  http-get https://:5000/healthz delay=0s timeout=5s period=10s #success=1 #failure=3
    Environment:
      REGISTRY_HTTP_ADDR:                   :5000
      REGISTRY_HTTP_NET:                    tcp
      REGISTRY_HTTP_SECRET:                 xeEy14G8IIpgkmQ5mA4UMC+XMhZgEfCy8JRvTN003oQ=
      REGISTRY_MIDDLEWARE_REPOSITORY_OPENSHIFT_ENFORCEQUOTA:    false
      REGISTRY_HTTP_TLS_KEY:                    /etc/secrets/registry.key
      REGISTRY_HTTP_TLS_CERTIFICATE:                /etc/secrets/registry.crt
    Mounts:
      /etc/secrets from registry-certificates (rw)
      /registry from registry-storage (rw)
  Volumes:
   registry-storage:
<span class="hll">    Type:   PersistentVolumeClaim (a reference to a PersistentVolumeClaim in the same namespace)
</span><span class="hll">    ClaimName:  registry-claim
</span>    ReadOnly:   false
   registry-certificates:
    Type:   Secret (a volume populated by a Secret)
    SecretName: registry-certificates
    Optional:   false

Deployment #2 (latest):
    Name:       docker-registry-2
    Created:    15 minutes ago
    Status:     Complete
    Replicas:   3 current / 3 desired
    Selector:   deployment=docker-registry-2,deploymentconfig=docker-registry,docker-registry=default
    Labels:     docker-registry=default,openshift.io/deployment-config.name=docker-registry
    Pods Status:    3 Running / 0 Waiting / 0 Succeeded / 0 Failed
Deployment #1:
    Created:    40 minutes ago
    Status:     Complete
    Replicas:   0 current / 0 desired

Events:
  FirstSeen LastSeen    Count   From                SubObjectPath   Type        Reason          Message
  --------- --------    -----   ----                -------------   --------    ------          -------
  40m       40m     1   deploymentconfig-controller         Normal      DeploymentCreated   Created new replication controller &quot;docker-registry-1&quot; for version 1
  15m       15m     1   deploymentconfig-controller         Normal      DeploymentCreated   Created new replication controller &quot;docker-registry-2&quot; for version 2
</pre></div>


<p>While the exact output will be different for you it is easy to tell the registry pods are configured to mount a <code>PersistentVolume</code> associated with the <code>PersistentVolumeClaim</code> named <code>registry-claim</code>.</p>
<p>&#8680; Verify this <code>PVC</code> exists:</p>
<div class="codehilite"><pre><span></span>oc get pvc/registry-claim
</pre></div>


<p>The <code>PVC</code> was automatically generated by <code>openshift-ansible</code>:</p>
<div class="codehilite"><pre><span></span>NAME             STATUS    VOLUME            CAPACITY   ACCESSMODES   STORAGECLASS   AGE
registry-claim   Bound     registry-volume   10Gi       RWX                          23m
</pre></div>


<p>In the OpenShift UI you will see the new Registry configuration when you log on as <code>operator</code> and check the <strong>Overview</strong> page in the <code>default</code> namespace:</p>
<p><a href="../img/registry_3way_dc.png"><img alt="Registry Deployment Scaled" src="../img/registry_3way_dc.png" /></a></p>
<p><code>openshift-ansible</code> generated an independent set of GlusterFS pods, a separate instance of <code>heketi</code> and a separate <code>StorageClass</code> as well. These components were configured to use the <code>infra-storage</code> namespace. Refer to Module 2 to get an understanding of those components if you just skipped to here.</p>
<p>&#8680; Verify there are at least 3 GlusterFS pods and one <code>heketi</code> pod:</p>
<div class="codehilite"><pre><span></span>oc get pods -n infra-storage
</pre></div>


<p>There is now dedicated a CNS stack including the <code>gluster-block</code> provisioner for OpenShift Infrastructure:</p>
<div class="codehilite"><pre><span></span>NAME                                           READY     STATUS    RESTARTS   AGE
glusterblock-registry-provisioner-dc-1-6wlcw   1/1       Running   0          24m
glusterfs-registry-2f2vk                       1/1       Running   0          27m
glusterfs-registry-kxghm                       1/1       Running   0          27m
glusterfs-registry-pjrfl                       1/1       Running   0          27m
heketi-registry-1-6rjth                        1/1       Running   0          25m
</pre></div>


<p>With this you have successfully remediated a single point of failure from your OpenShift installation. Since this setup is entirely automated by <code>openshift-ansible</code> you can deploy out of the box an OpenShift environment capable of hosting stateful applications and operate a fault-tolerant registry. All this with no external dependencies or complicated integration of external storage :)</p>
<hr />
<h2 id="openshift-loggingmetrics-on-cns-block-storage">OpenShift Logging/Metrics on CNS block storage<a class="headerlink" href="#openshift-loggingmetrics-on-cns-block-storage" title="Permanent link">#</a></h2>
<p>OpenShift Logging (Kibana) and Metrics (Cassandra) are also components that require persistent storage. Typically so far external block storage providers had to be used in order to get these services to work reliably.<br />
Since the introduction of <code>gluster-block</code> this is now possible with CNS as well.</p>
<p>It might seem counter-intuitive at first to consider CNS to serve these systems, mainly because:</p>
<ul>
<li>Kibana and Cassandra are shared-nothing scale-out services</li>
<li>CNS provides shared filesystem storage whereas for Kibana/Cassandra a block storage device formatted with a local filesystem like XFS would be enough</li>
</ul>
<p>Here are a couple of reasons why it is still a good idea to run those on CNS:</p>
<ul>
<li>the total amount of storage available infra nodes is typically limited in capacity (CNS can scale beyond that)</li>
<li>the storage type available in infra nodes is most likely not suitable for performant long-term operations of these services (CNS uses aggregate performance of multiple devices and hosts)</li>
<li>without CNS some sort external storage system is required that requires additional manual configuration steps, in any case you should not use <code>emptyDir</code></li>
</ul>
<h4 id="completing-gluster-block-setup">Completing <code>gluster-block</code> setup<a class="headerlink" href="#completing-gluster-block-setup" title="Permanent link">#</a></h4>
<p>With the execution of previous playbook we have also deployed and configured <code>gluster-block</code>. The required settings were all in the Ansible inventory file. Note that while the registry will consume a normal CNS volume based on <code>gluster-fuse</code>, GlusterFS&rsquo; native file protocol, the only supported form of CNS backing both OpenShift Logging and/or Metrics is <code>gluster-block</code>.</p>
<div class="admonition tip">
<p class="admonition-title">A quick primer to <code>gluster-block</code></p>
<p><code>gluster-block</code> is a block-storage provisioner based on CNS. It is implemented using a large GlusterFS volume that hosts sparse files which in turn are the backing files of iSCSI LUNs served by <code>gluster-block</code>. The orchestration of this taken care of by the <code>gluster-block-provisioner</code> which runs in a pod just like <code>heketi</code>.<br />
Even though the result of this are iSCSI LUNs, i.e. block devices, this kind of storage, when claimed, still ends up being mounted by OpenShift nodes and then formatted with XFS (like for any other block storage in OpenShift). As a consequence <code>gluster-block</code> only supports <code>RWO</code> volumes.</p>
<p>So you may ask: is this, an XFS-formatted iSCSI LUN backed by a sparse file on top of GlusterFS, still faster than a plain GlusterFS volume? The answer is yes for applications like OpenShift Metrics and Logging. Such applications regularly do file-system operations like locking or byte-range locking which are very expensive on any distributed filesystem, and GlusterFS is no exception. On local filesystems like XFS this is not a problem. The resulting XFS meta-data operations are not distributed in <code>gluster-block</code> but are perceived as plain I/O to a file on top of GlusterFS, which is fast.</p>
</div>
<p>By default <code>openshift-ansible</code> will stand up the <code>gluster-block</code> infrastructure as part of deploying CNS but it will not configure the nodes to mount iSCSI volumes with multipathing. The process involves installing the <code>iscsi-initiator-utils</code> as well as <code>device-mapper-multipath</code>, and then enable / configure the <code>multipathd</code> service.<br />
This has already been prepared for you in this environment. For more details on the steps, consult the <a href="https://access.redhat.com/documentation/en-us/red_hat_gluster_storage/3.3/html-single/container-native_storage_for_openshift_container_platform/#Block_Storage">documentation</a>.</p>
<p>The only configuration step left is to create a <code>StorageClass</code> for <code>gluster-block</code> and temporarily make it the default so the playbooks which provision OpenShift Logging and Metrics get their PVCs fulfilled by <code>gluster-block</code>.</p>
<p>First, make sure you are logged in as <code>operator</code> in the <code>infra-storage</code> namespace:</p>
<div class="codehilite"><pre><span></span>oc login -u operator -n infra-storage
</pre></div>


<p>Then, programmatically determine the auto-generated credentials for the <code>heketi</code> pod and the cluster ID for the CNS cluster serving the registry:</p>
<div class="codehilite"><pre><span></span>HEKETI_POD=$(oc get pods -l glusterfs=heketi-registry-pod -n infra-storage -o jsonpath=&quot;{.items[0].metadata.name}&quot;)
export HEKETI_CLI_SERVER=http://$(oc get route/heketi-registry -o jsonpath=&#39;{.spec.host}&#39;)
export HEKETI_CLI_USER=admin
export HEKETI_CLI_KEY=$(oc get pod/$HEKETI_POD -o jsonpath=&#39;{.spec.containers[0].env[?(@.name==&quot;HEKETI_ADMIN_KEY&quot;)].value}&#39;)
export CNS_INFRA_CLUSTER=$(heketi-cli cluster list --json | jq -r &#39;.clusters[0]&#39;)
</pre></div>


<p>The, create YAML representation of the <code>secret</code> to store the credentials for the <code>heketi</code> pod by copy&amp;pasting the following command (inserts the credentials from the environment variable for you convenience):</p>
<div class="codehilite"><pre><span></span>cat &gt; gluster-block-secret.yml &lt;&lt;EOF
apiVersion: v1
kind: Secret
metadata:
  name: heketi-secret
  namespace: infra-storage
data:
  # base64 encoded password. E.g.: echo -n &quot;mypassword&quot; | base64
  key: ${HEKETI_CLI_KEY}
type: gluster.org/glusterblock
EOF
</pre></div>


<p>Create the <code>secret</code>:</p>
<div class="codehilite"><pre><span></span>oc create -f gluster-block-secret.yml
</pre></div>


<p>Now create the actual <code>StorageClass</code> for <code>gluster-block</code>, again by running this command that creates the file with the right content and saves you from typing:</p>
<div class="codehilite"><pre><span></span>cat &gt; gluster-block-storageclass.yml &lt;&lt;EOF
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
 name: gluster-block
provisioner: gluster.org/glusterblock
parameters:
 resturl: &quot;${HEKETI_CLI_SERVER}&quot;
 restuser: &quot;${HEKETI_CLI_USER}&quot;
 restsecretnamespace: &quot;infra-storage&quot;
 restsecretname: &quot;heketi-secret&quot;
 hacount: &quot;3&quot;
 clusterids: &quot;${CNS_INFRA_CLUSTER}&quot;
 chapauthenabled: &quot;true&quot;
EOF
</pre></div>


<p>Now create the <code>StorageClass</code>:</p>
<div class="codehilite"><pre><span></span>oc create -f gluster-block-storageclass.yml
</pre></div>


<p>To review the required configuration sections in the <code>openshift-ansible</code> inventory file, open the standard inventory file <code>/etc/ansible/ocp-with-glusterfs-registry</code> that was used to deploy this OCP cluster initially:</p>
<p><kbd>/etc/ansible/ocp-with-glusterfs-registry:</kbd></p>
<div class="codehilite"><pre><span></span><span class="k">[OSEv3:children]</span>
<span class="na">masters</span>
<span class="na">nodes</span>

<span class="k">[OSEv3:vars]</span>
<span class="na">deployment_type</span><span class="o">=</span><span class="s">openshift-enterprise</span>
<span class="na">containerized</span><span class="o">=</span><span class="s">true</span>
<span class="na">openshift_image_tag</span><span class="o">=</span><span class="s">v3.7.14</span>
<span class="na">openshift_master_identity_providers</span><span class="o">=</span><span class="s">[{&#39;name&#39;: &#39;htpasswd&#39;, &#39;login&#39;: &#39;true&#39;, &#39;challenge&#39;: &#39;true&#39;, &#39;kind&#39;: &#39;HTPasswdPasswordIdentityProvider&#39;, &#39;filename&#39;: &#39;/etc/origin/master/htpasswd&#39;}]</span>
<span class="na">openshift_master_htpasswd_users</span><span class="o">=</span><span class="s">{&#39;developer&#39;: &#39;$apr1$bKWroIXS$/xjq07zVg9XtH6/VKuh6r/&#39;,&#39;operator&#39;: &#39;$apr1$bKWroIXS$/xjq07zVg9XtH6/VKuh6r/&#39;}</span>
<span class="na">openshift_master_default_subdomain</span><span class="o">=</span><span class="s">&#39;cloudapps.52.59.170.248.xip.ioopenshift_router_selector=&#39;role=master&#39;</span>
<span class="na">openshift_hosted_router_wait</span><span class="o">=</span><span class="s">false</span>
<span class="na">openshift_registry_selector</span><span class="o">=</span><span class="s">&#39;role=infra&#39;</span>
<span class="na">openshift_hosted_registry_wait</span><span class="o">=</span><span class="s">false</span>
<span class="na">openshift_hosted_registry_storage_volume_size</span><span class="o">=</span><span class="s">10Gi</span>
<span class="na">openshift_hosted_registry_storage_kind</span><span class="o">=</span><span class="s">glusterfs</span>
<span class="na">openshift_hosted_registry_storage_glusterfs_swap</span><span class="o">=</span><span class="s">true</span>
<span class="na">openshift_hosted_registry_storage_glusterfs_swapcopy</span><span class="o">=</span><span class="s">true</span>
<span class="na">openshift_metrics_install_metrics</span><span class="o">=</span><span class="s">false</span>
<span class="na">openshift_metrics_hawkular_hostname</span><span class="o">=</span><span class="s">&quot;hawkular-metrics.{{ openshift_master_default_subdomain }}&quot;</span>
<span class="hll"><span class="na">openshift_metrics_cassandra_storage_type</span><span class="o">=</span><span class="s">pv</span>
</span><span class="hll"><span class="na">openshift_metrics_cassandra_pvc_size</span><span class="o">=</span><span class="s">10Gi</span>
</span><span class="na">openshift_logging_install_logging</span><span class="o">=</span><span class="s">false</span>
<span class="hll"><span class="na">openshift_logging_es_pvc_size</span><span class="o">=</span><span class="s">10Gi</span>
</span><span class="hll"><span class="na">openshift_logging_es_pvc_dynamic</span><span class="o">=</span><span class="s">true</span>
</span>
<span class="k">[... output omitted... ]</span>
</pre></div>


<p>The highlighted lines indicate the settings that are required in order to put the Cassandra database of the OpenShift Metrics service on a <code>PersistentVolume</code> (<code>openshift_metrics_cassandra_storage_type=pv</code>) and how large this volume should be (<code>openshift_metrics_cassandra_pvc_size=10Gi</code>).<br />
Similarly the backend for the ElasticSearch component of OpenShift Logging is set to <code>PersistentVolume</code> (<code>openshift_logging_es_pvc_dynamic=true</code>) and the size is specifed (<code>openshift_logging_es_pvc_size=10Gi</code>).<br />
With these settings in place <code>openshift-ansible</code> will request <code>PVC</code> object for these services.</p>
<p>Unfortunately <code>openshift-ansible</code> today is lacking the ability to specify a certain <code>StorageClass</code> with those <code>PVCs</code>, so we have to make the CNS cluster that was created above temporarily the system-wide default.</p>
<p>&#8680; Login as <code>operator</code> to the <code>openshift-infra</code> namespace:</p>
<div class="codehilite"><pre><span></span>oc login -u operator -n openshift-infra
</pre></div>


<p>&#8680; First, if you deployed the general-purpose CNS cluster in <a href="../../module-2-deploy-cns/">Module 2</a>, you need to disable the other <code>StorageClass</code> <code>glusterfs-storage</code> from the other CNS stack as being the default:</p>
<div class="codehilite"><pre><span></span>oc patch storageclass glusterfs-storage \
-p &#39;{&quot;metadata&quot;: {&quot;annotations&quot;: {&quot;storageclass.kubernetes.io/is-default-class&quot;: &quot;false&quot;}}}&#39;
</pre></div>


<p>&#8680; Then, use the <code>oc patch</code> command again to change the definition of the <code>StorageClass</code> on the fly:</p>
<div class="codehilite"><pre><span></span>oc patch storageclass glusterfs-registry \
-p &#39;{&quot;metadata&quot;: {&quot;annotations&quot;: {&quot;storageclass.kubernetes.io/is-default-class&quot;: &quot;true&quot;}}}&#39;
</pre></div>


<p>&#8680; Verify that now the <code>StorageClass</code> <code>glusterfs-registry</code> is the default:</p>
<div class="codehilite"><pre><span></span>oc get storageclass
</pre></div>


<div class="codehilite"><pre><span></span>NAME                           TYPE
<span class="hll">glusterfs-registry (default)   kubernetes.io/glusterfs
</span>glusterfs-storage              kubernetes.io/glusterfs
</pre></div>


<h4 id="deploying-openshift-metrics-with-persistent-storage-from-cns">Deploying OpenShift Metrics with Persistent Storage from CNS<a class="headerlink" href="#deploying-openshift-metrics-with-persistent-storage-from-cns" title="Permanent link">#</a></h4>
<p>The inventory file <code>/etc/ansible/hosts</code> as explained has all the required options set to run Logging/Metrics on dynamic provisioned storage supplied via a <code>PVC</code>. The only variable that we need to override is (<code>openshift_metrics_install_metrics</code>) to actually invoke the required playbooks the installation.</p>
<p>&#8680; Execute the Metrics deployment playbook like this:</p>
<div class="codehilite"><pre><span></span>ansible-playbook -i /etc/ansible/hosts \
    -e openshift_metrics_install_metrics=True \
    /usr/share/ansible/openshift-ansible/playbooks/byo/openshift-cluster/openshift-metrics.yml
</pre></div>


<p>This takes about 1-2 minutes to complete. However the deployment is not quite finished yet.</p>
<p>&#8680; Use the <code>watch</code> command to wait for the <code>hawkular-metrics</code> pod to be in <code>READY</code> state.</p>
<div class="codehilite"><pre><span></span>watch oc get pods -l name=hawkular-metrics
</pre></div>


<p>Exit out of the watch mode with: <kbd>Ctrl</kbd> + <kbd>c</kbd></p>
<p>It will be ready when the database (Cassandra) finished initializing. Alternatively in the UI observe the deployment in the <strong>Overview</strong> pane, focussing on the <code>hawkular-metrics</code> deployment:</p>
<p><a href="../img/waiting_for_metrics_on_cns.png"><img alt="Waiting on OpenShift Metrics to be deployed" src="../img/waiting_for_metrics_on_cns.png" /></a></p>
<p>After 2-3 minutes all 3 pods, that make up the OpenShift Metrics service, should be ready:</p>
<p>&#8680; Verify all pods in the namespace have a <code>1/1</code> in the <code>READY</code> column:</p>
<div class="codehilite"><pre><span></span>oc get pods
</pre></div>


<div class="codehilite"><pre><span></span>NAME                         READY     STATUS    RESTARTS   AGE
hawkular-cassandra-1-sxctx   1/1       Running   0          5m
hawkular-metrics-895xz       1/1       Running   0          5m
heapster-pjxpp               1/1       Running   0          5m
</pre></div>


<p>To use the Metrics service you need to logon / reload the OpenShift UI in your browser. You will then see a warning message like this one:</p>
<p><a href="../img/metrics_warning.png"><img alt="OpenShift Metrics Warning" src="../img/metrics_warning.png" /></a></p>
<p>Don&rsquo;t worry - this is due to self-signed SSL certificates in this environment.</p>
<p>&#8680; Click the <strong>Open Metrics URL</strong> link and accept the self-signed certificate in your new browser tab. You will see the status page of the OpenShift Hawkular Metrics component:</p>
<p><a href="../img/metrics_hawkular.png"><img alt="OpenShift Metrics Hawkular" src="../img/metrics_hawkular.png" /></a></p>
<p>&#8680; Then go back to the overview page. Next to the pods monitoring graphs for CPU, memory and network consumption will appear:</p>
<p><a href="../img/metrics_graphs.png"><img alt="OpenShift Metrics Graphs" src="../img/metrics_graphs.png" /></a></p>
<p>If you change to the <strong>Storage</strong> menu in the OpenShift UI you will also see the <code>PVC</code> that <code>openshift-ansible</code> has set up for the Cassandra pod.</p>
<p><a href="../img/metrics_pvc.png"><img alt="OpenShift Metrics PVC" src="../img/metrics_pvc.png" /></a></p>
<p>Congratulations. You have successfully deploy OpenShift Metrics using scalable, fault-tolerant and persistent storage. The data that you see visualized in the UI is stored on a <code>PersistentVolume</code> served by CNS.</p>
<div class="admonition note">
<p class="admonition-title">Preview</p>
<p>This was a preview of the general process. Note that this will be supported for production with the release of CNS 3.6.</p>
</div>
<h4 id="deploying-openshift-logging-with-persistent-storage-from-cns">Deploying OpenShift Logging with Persistent Storage from CNS<a class="headerlink" href="#deploying-openshift-logging-with-persistent-storage-from-cns" title="Permanent link">#</a></h4>
<p>In a very similar fashion you can install OpenShift Logging Services, run by Kibana and ElasticSearch.</p>
<p>&#8680; As <code>operator</code>, login in to the <code>logging</code> namespace:</p>
<div class="codehilite"><pre><span></span>oc login -u operator -n logging
</pre></div>


<p>&#8680; Execute the Logging deployment playbook like this:</p>
<div class="codehilite"><pre><span></span>ansible-playbook -i /etc/ansible/hosts \
  -e openshift_logging_install_logging=true \
  /usr/share/ansible/openshift-ansible/playbooks/byo/openshift-cluster/openshift-logging.yml
</pre></div>


<p>After 1-2 minutes the playbook finishes and you have a number of new pods in the <code>logging</code> namespace:</p>
<p>&#8680; List all the ElasticSearch pods that aggregate and store the logs:</p>
<div class="codehilite"><pre><span></span>oc get pods -l component=es
</pre></div>


<p>This pod runs a single ElasticSearch instance.</p>
<div class="codehilite"><pre><span></span>NAME                                      READY     STATUS    RESTARTS   AGE
logging-es-data-master-kcbtgll3-1-vb34h   1/1       Running   0          11m
</pre></div>


<p>&#8680; List the Kibana pod:</p>
<div class="codehilite"><pre><span></span>oc get pods -l component=kibana
</pre></div>


<p>This pod runs the Kibana front-end to query and search through logs:</p>
<div class="codehilite"><pre><span></span>NAME                     READY     STATUS    RESTARTS   AGE
logging-kibana-1-1c2dj   2/2       Running   0          11m
</pre></div>


<p>&#8680; List all Fluentd pods:</p>
<div class="codehilite"><pre><span></span>oc get pods -l component=fluentd
</pre></div>


<p>These pods run as part of a <code>DaemonSet</code> and are responsible for collecting and shipping the various logs from all nodes to the ElasticSearch instance.</p>
<div class="codehilite"><pre><span></span>NAME                    READY     STATUS    RESTARTS   AGE
logging-fluentd-3k7nh   1/1       Running   0          5m
logging-fluentd-473cf   1/1       Running   0          4m
logging-fluentd-9kgsv   1/1       Running   0          5m
logging-fluentd-h8fhb   1/1       Running   0          4m
logging-fluentd-pb6h8   1/1       Running   0          4m
logging-fluentd-q6lv4   1/1       Running   0          4m
logging-fluentd-r455n   1/1       Running   0          4m
logging-fluentd-v34ll   1/1       Running   0          5m
logging-fluentd-vxnd3   1/1       Running   0          5m
logging-fluentd-wf3lr   1/1       Running   0          5m
</pre></div>


<p>Switch to the OpenShift UI and as <code>operator</code> select the <code>logging</code> project. In the <strong>Overview</strong> section you&rsquo;ll a <code>Route</code> for the Kibana deployment created. <strong>Click</strong> the link on the <code>Route</code> to open the Kibana UI in a new browser tab and verify the Kibana deployment is healthy.</p>
<p><a href="../img/kibana_pod_ready.png"><img alt="OpenShift Logging Pods" src="../img/kibana_pod_ready.png" /></a></p>
<p>The public URL for the Kibana UI will be visible in the <strong>ROUTES</strong> section of the <code>logging-kibana</code> deployment.</p>
<p><a href="../img/kibana_ui_loading.png"><img alt="OpenShift Logging UI" src="../img/kibana_ui_loading.png" /></a></p>
<p>When you are logging on for the first time Kibana will ask for credentials.<br />
Use your OpenShift <code>operator</code> account with the password <code>r3dh4t</code>.</p>
<p>After logging in you will see that Kibana has started indexing the database, which is hosted on CNS by ElasticSearch.</p>
<p><a href="../img/kibana_es_indexing.png"><img alt="OpenShift Logging Indexing" src="../img/kibana_es_indexing.png" /></a></p>
<p>This shows that ElasticSearch search running of CNS-provided <code>PersistentVolume</code> successfully. It will take some time to complete the first indexing.</p>
                
                  
                
              
              
                
              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
        
          <a href="../module-4-cluster-ops/" title="Module 4 - Cluster Operations" class="md-flex md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-back md-footer-nav__button"></i>
            </div>
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  Previous
                </span>
                Module 4 - Cluster Operations
              </span>
            </div>
          </a>
        
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
          <div class="md-footer-copyright__highlight">
            Copyright 2018 Red Hat, Inc.
          </div>
        
        powered by
        <a href="http://www.mkdocs.org">MkDocs</a>
        and
        <a href="https://squidfunk.github.io/mkdocs-material/">
          Material for MkDocs</a>
      </div>
      
        
      
    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../assets/javascripts/application.cae2244d.js"></script>
      
      <script>app.initialize({version:"0.17.2",url:{base:".."}})</script>
      
    
    
      
    
  </body>
</html>